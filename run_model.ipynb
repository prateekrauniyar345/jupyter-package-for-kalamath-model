{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import tempfile\n",
    "import fiona\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import traceback\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# warning messages\n",
    "message = {}\n",
    "\n",
    "# get the shapefile folder\n",
    "shapefile_folder = os.path.join(cwd, 'shapefile')\n",
    "# Pattern to match shapefile (shapefile typically have extensions like .shp)\n",
    "shapefile_pattern = os.path.join(shapefile_folder, '*.shp')\n",
    "\n",
    "shapefiles_list = glob.glob(shapefile_pattern)\n",
    "# print(shapefiles_list)\n",
    "\n",
    "# Count the number of shapefile\n",
    "num_shapefiles = len(shapefiles_list)\n",
    "# print(num_shapefiles)\n",
    "\n",
    "# get the java folder\n",
    "java_folder = os.path.join(cwd, 'source/java')\n",
    "\n",
    "# get the csv folder\n",
    "csv_folder = os.path.join(cwd, 'source/csv_files')\n",
    "# Ensure the output directory exists and remove all existing CSV files in the output folder\n",
    "if os.path.exists(csv_folder):\n",
    "    for file in glob.glob(os.path.join(csv_folder, '*.csv')):\n",
    "        os.remove(file)\n",
    "    else:\n",
    "        os.makedirs(csv_folder, exist_ok=True)\n",
    "# get the modified csv folder path\n",
    "modified_csv_folder = os.path.join(cwd, 'source/modified_csv_for_curr_QMD')\n",
    "if os.path.exists(modified_csv_folder):\n",
    "        for file in glob.glob(os.path.join(modified_csv_folder, '*.csv')):\n",
    "            os.remove(file)\n",
    "        else:\n",
    "            os.makedirs(modified_csv_folder, exist_ok=True)\n",
    "result_folder = os.path.join(cwd, 'result')\n",
    "if os.path.exists(result_folder):\n",
    "        for file in glob.glob(os.path.join(result_folder, '*.csv')):\n",
    "            os.remove(file)\n",
    "        else:\n",
    "            os.makedirs(result_folder, exist_ok=True)\n",
    "# get the raster file\n",
    "raster_folder = os.path.join(cwd,'source/rasters')\n",
    "tiffile = os.path.join(raster_folder,'kl_comp.tif')\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_standID_for_generatingCSV_for_CurrQMD(lis):\n",
    "    dic_for_standID_with_currQMD = {}\n",
    "    for item in lis:\n",
    "        if 'curr_QMD' in item and 'curr_TPA' in item:\n",
    "            try:\n",
    "                # Convert the values to floats\n",
    "                curr_qmd = float(item['curr_QMD'][0])\n",
    "                curr_tpa = float(item['curr_TPA'][0])\n",
    "                # Check if the values are not NaN and not zero\n",
    "                if not np.isnan(curr_qmd) and not np.isnan(curr_tpa) and curr_qmd != 0 and curr_tpa != 0:\n",
    "                    stand_id = int(item['StandID'][0])\n",
    "                    dic_for_standID_with_currQMD[stand_id] = [int(item['curr_QMD'][0]),int(item['curr_TPA'][0])]\n",
    "            except (ValueError, TypeError):\n",
    "                print(\"absence due to invalid values\")\n",
    "    return dic_for_standID_with_currQMD\n",
    "\n",
    "        \n",
    "# dic = filter_standID_for_generatingCSV_for_CurrQMD(fields_from_shapefile)\n",
    "# print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the numbers to characters\n",
    "def number_to_letters_fast(nums):\n",
    "    results = []\n",
    "    # Iterate over the numbers\n",
    "    for n in nums:\n",
    "        letter = ''\n",
    "        while n > 0:\n",
    "            n -= 1  \n",
    "            letter = chr(n % 26 + 97) + letter  \n",
    "            n //= 26  \n",
    "        results.append(letter)  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(out_image, csv_folder, index, parameters, csv_files, stand_id, dict_for_standIDnCrrnQMD_from_allFields, csv_with_modified_qmd):\n",
    "        \"\"\"\n",
    "        Process the raster file and save the band data to CSV files for each shape.\n",
    "\n",
    "        Parameters:\n",
    "        - out_image (numpy array): Masked raster data.\n",
    "        - model_parameters (dict): Dictionary containing shape parameters.\n",
    "        - output_folder (str): Folder to save the CSV files.\n",
    "        Returns:\n",
    "        - List of CSV filenames.\n",
    "        \"\"\"     \n",
    "        os.makedirs(csv_folder, exist_ok=True)\n",
    "        column_names = ['CMI_wt','dem30_usa','Subz_Name','M_PPT01','PRATIO','B_SHM','USA_Slope','M_Tmin03','TOTAL_LITH','IFC_Solar']\n",
    "\n",
    "\n",
    "        with rasterio.open(tiffile) as src:\n",
    "            # Flatten band data and create DataFrame\n",
    "            band_data = {f'band_{j+1}': out_image[j].flatten() for j in range(out_image.shape[0])}\n",
    "            df = pd.DataFrame(band_data)\n",
    "            # Replace the nodata values with NaN\n",
    "            for band in band_data:\n",
    "                df[band] = df[band].replace(src.nodata, np.nan)\n",
    "            df_cleaned = df    \n",
    "            if not df_cleaned.empty:\n",
    "                if len(column_names) >= df_cleaned.shape[1]:\n",
    "                    df_cleaned.columns = column_names[:df_cleaned.shape[1]]\n",
    "                # Extend the csv file with the model parameters\n",
    "                param_df = pd.DataFrame({key: [value[0]] * len(df_cleaned) for key, value in parameters.items()})\n",
    "                df_extended = pd.concat([df_cleaned, param_df], axis=1)\n",
    "                # drop the NaN values\n",
    "                df_extended = df_extended.dropna()\n",
    "                cols = ['Subz_Name', 'TOTAL_LITH']\n",
    "                df_extended[cols] = df_extended[cols].astype('int')\n",
    "                for col in cols:\n",
    "                    df_extended[col] = number_to_letters_fast(df_extended[col].values)\n",
    "                # Save to CSV\n",
    "                csv_filename = f\"csv_for_stand_{stand_id}.csv\"\n",
    "                csv_path = os.path.join(csv_folder, csv_filename)\n",
    "                csv_files.append(csv_path)\n",
    "                df_extended.to_csv(csv_path, index=False)\n",
    "                if stand_id in dict_for_standIDnCrrnQMD_from_allFields:\n",
    "                     Current_QMD =  dict_for_standIDnCrrnQMD_from_allFields[stand_id]\n",
    "                     print(Current_QMD)\n",
    "                     df_extended['QMD'] = Current_QMD[0]\n",
    "                     new_file_name = f\"with_cur_QMD_{csv_filename}\"\n",
    "                     csv_with_modified_qmd.append(os.path.join(modified_csv_folder, new_file_name))\n",
    "                     df_extended.to_csv(os.path.join(modified_csv_folder, new_file_name), index=False)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 700]\n",
      "[11, 400]\n",
      "[12, 390]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# csvfile list\n",
    "csv_files = []\n",
    "# Define desired columns\n",
    "desired_columns = ['QMD','PM_PROP','TO_PROP','DF_PROP','SP_PROP','OH_PROP', 'OC_PROP','WH_PROP','GF_PROP','WF_PROP']\n",
    "\n",
    "stand_id = []\n",
    "# --------------------\n",
    "stand_id = []\n",
    "fields_from_shapefile = []\n",
    "dict_for_standIDnCrrnQMD_from_allFields = {}\n",
    "csv_with_current_qmd_and_tpa = []\n",
    "# ---------------------\n",
    "\n",
    "if os.path.exists(csv_folder):\n",
    "    for file in glob.glob(os.path.join(csv_folder, '*.csv')):\n",
    "        os.remove(file)\n",
    "else:\n",
    "    os.makedirs(csv_folder, exist_ok=True)\n",
    "\n",
    "for shapefile in shapefiles_list:\n",
    "    # Path to shapefile\n",
    "    shapefile_path = shapefile\n",
    "    # Read the main shapefile\n",
    "    try:\n",
    "        ply = gpd.read_file(shapefile_path)\n",
    "    except Exception as ex:\n",
    "        print(f\"Unable to read shapefile  {shapefile_path}. Your file may be corrupt: {ex}\")\n",
    "        raise\n",
    "\n",
    "    # Change CRS to match raster\n",
    "    ply = ply.to_crs(epsg=3857)\n",
    "    with tempfile.NamedTemporaryFile() as tf:\n",
    "        crsName = tf.name\n",
    "    ply.to_file(crsName)  # Write new shapefile \n",
    "    # Read and process shapefile\n",
    "    with rasterio.open(tiffile) as geotiff:\n",
    "        with fiona.open(crsName, \"r\") as shapefile:\n",
    "            shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "            for index, shape in enumerate(shapes):\n",
    "                try:\n",
    "                    out_image, out_transform = rasterio.mask.mask(geotiff, [shape], crop=True, all_touched=True)                 \n",
    "                    # Extract desired columns from the clipped shapefile\n",
    "                    clipped_shapefile = ply.clip(gpd.GeoDataFrame(geometry=[shape], crs=ply.crs))\n",
    "                    fields_from_shapefile.append(clipped_shapefile.copy().to_dict(orient='list'))\n",
    "                    dict_for_standIDnCrrnQMD_from_allFields = filter_standID_for_generatingCSV_for_CurrQMD(fields_from_shapefile)\n",
    "                    extracted_data = clipped_shapefile[desired_columns].copy()\n",
    "                    desired_columns = ['QMD','PM_PROP','TO_PROP','DF_PROP','SP_PROP','OH_PROP', 'OC_PROP','WH_PROP','GF_PROP','WF_PROP']\n",
    "                    extracted_data[\"W_ShadeTol\"] = extracted_data[\"PM_PROP\"] * 1.17 + extracted_data[\"TO_PROP\"] * 3.67 + extracted_data[\"DF_PROP\"] * 2.78 + extracted_data[\"SP_PROP\"] * 2.66 + extracted_data[\"OH_PROP\"] * 3 + extracted_data[\"OC_PROP\"] * 2.5 + extracted_data[\"WH_PROP\"] * 4.96+ extracted_data[\"GF_PROP\"] * 4.01 + extracted_data[\"WF_PROP\"] * 4.33\n",
    "                    extracted_data[\"W_DroughtTol\"] = extracted_data[\"PM_PROP\"] * 4.97 + extracted_data[\"TO_PROP\"] * 4 + extracted_data[\"DF_PROP\"] * 2.62 + extracted_data[\"SP_PROP\"] * 2.67 + extracted_data[\"OH_PROP\"] * 3 + extracted_data[\"OC_PROP\"] * 2.5 + extracted_data[\"WH_PROP\"] * 1.17 + extracted_data[\"GF_PROP\"] * 2.33 + extracted_data[\"WF_PROP\"] * 1.91                 \n",
    "                    # Extract StandID as integer and append to stand_id list -- we are getting this stand id from shapefile \n",
    "                    stand_id_value = int(clipped_shapefile['StandID'].values[0])\n",
    "                    stand_id.append(stand_id_value)                  \n",
    "                    # Convert the extracted data to a dictionary\n",
    "                    extracted_data_dict_list = extracted_data.to_dict(orient='records')\n",
    "                    # convert the list of dictionaries into a single dictionary if needed\n",
    "                    extracted_data_dict = extracted_data.to_dict(orient='list')\n",
    "                    # Call to_csv function to create and save the CSV file\n",
    "                    to_csv(out_image, csv_folder, index, extracted_data_dict, csv_files, stand_id[-1], dict_for_standIDnCrrnQMD_from_allFields, csv_with_current_qmd_and_tpa)\n",
    "                except Exception as ex:\n",
    "                    print(f\"Error processing shape {index}: {str(ex)}\")\n",
    "                    traceback.print_exc()  # Print the full traceback\n",
    "                    print(\"\\n\")\n",
    "                    print(\"\\n\")\n",
    "                    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Id': [0], 'StandID': [101.0], 'QMD': [10.0], 'PM_PROP': [0.0], 'TO_PROP': [0.0], 'DF_PROP': [1.0], 'SP_PROP': [0.0], 'OH_PROP': [0.0], 'OC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'WF_PROP': [0.0], 'curr_QMD': [8.0], 'curr_TPA': [700.0], 'geometry': [<POLYGON ((-13703980.358 5306951.356, -13723331.137 5306951.356, -13714865.1...>]}, {'Id': [0], 'StandID': [102.0], 'QMD': [10.0], 'PM_PROP': [0.0], 'TO_PROP': [0.0], 'DF_PROP': [1.0], 'SP_PROP': [0.0], 'OH_PROP': [0.0], 'OC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'WF_PROP': [0.0], 'curr_QMD': [11.0], 'curr_TPA': [400.0], 'geometry': [<POLYGON ((-13699948.89 5198320.633, -13711161.985 5196218.178, -13710110.75...>]}, {'Id': [0], 'StandID': [103.0], 'QMD': [10.0], 'PM_PROP': [0.0], 'TO_PROP': [0.0], 'DF_PROP': [0.0], 'SP_PROP': [0.0], 'OH_PROP': [0.2], 'OC_PROP': [0.8], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'WF_PROP': [0.0], 'curr_QMD': [12.0], 'curr_TPA': [390.0], 'geometry': [<POLYGON ((-13653344.465 5053251.22, -13652293.238 5062712.269, -13641780.96...>]}, {'Id': [0], 'StandID': [104.0], 'QMD': [10.0], 'PM_PROP': [0.0], 'TO_PROP': [0.0], 'DF_PROP': [0.0], 'SP_PROP': [0.0], 'OH_PROP': [0.0], 'OC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [1.0], 'WF_PROP': [0.0], 'curr_QMD': [nan], 'curr_TPA': [nan], 'geometry': [<POLYGON ((-13740596.358 4946026.002, -13736041.039 4941120.273, -13739194.7...>]}, {'Id': [0], 'StandID': [105.0], 'QMD': [10.0], 'PM_PROP': [0.0], 'TO_PROP': [0.0], 'DF_PROP': [0.0], 'SP_PROP': [0.0], 'OH_PROP': [0.0], 'OC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [1.0], 'WF_PROP': [0.0], 'curr_QMD': [nan], 'curr_TPA': [nan], 'geometry': [<POLYGON ((-13587128.972 5016826.377, -13584247.845 4992467.765, -13603891.8...>]}, {'Id': [0], 'StandID': [106.0], 'QMD': [10.0], 'PM_PROP': [0.0], 'TO_PROP': [0.0], 'DF_PROP': [1.0], 'SP_PROP': [0.0], 'OH_PROP': [0.0], 'OC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'WF_PROP': [0.0], 'curr_QMD': [nan], 'curr_TPA': [nan], 'geometry': [<POLYGON ((-13670337.987 4807898.435, -13721294.516 4776924.859, -13715299.6...>]}, {'Id': [0], 'StandID': [107.0], 'QMD': [10.0], 'PM_PROP': [0.0], 'TO_PROP': [0.0], 'DF_PROP': [1.0], 'SP_PROP': [0.0], 'OH_PROP': [0.0], 'OC_PROP': [0.0], 'WH_PROP': [0.0], 'GF_PROP': [0.0], 'WF_PROP': [0.0], 'curr_QMD': [nan], 'curr_TPA': [nan], 'geometry': [<POLYGON ((-13770473.362 5197076.832, -13817946.464 5202806.344, -13785206.3...>]}]\n"
     ]
    }
   ],
   "source": [
    "print(fields_from_shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code will filter out the csv that are not empty and can be fed to model.\n",
    "\n",
    "def filter_csv(folder_path):\n",
    "    # List all CSV files in the folder\n",
    "    csv_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    if csv_files is None:\n",
    "        return \n",
    "    # Initialize a list to store the 'stand' values from non-empty CSV files\n",
    "    stand_id_result = []\n",
    "    csv_for_result = []\n",
    "    # Check each CSV file\n",
    "    for files in csv_files:\n",
    "        try:\n",
    "            df = pd.read_csv(files)  # Read the CSV file into a DataFrame\n",
    "            if not df.empty:  # If the CSV file is not empty\n",
    "                # Extract the 'stand' value from the file name\n",
    "                csv_for_result.append(files)\n",
    "                filename = os.path.basename(files)  # Get the file name without the path\n",
    "                stand = filename.split('_')[-1].split('.')[0]  # Extract the 'stand' part\n",
    "                stand_id_result.append(stand)  # Add the 'stand' to the list\n",
    "        except pd.errors.EmptyDataError:\n",
    "            # Handle the case where the CSV file is empty or invalid\n",
    "            print(f\"{file} is empty or has no valid data.\")\n",
    "    return csv_for_result, stand_id_result\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prediction(csv_for_result):\n",
    "    # Compile and run Java code with subprocess\n",
    "    cwd = os.getcwd()  # Assuming cwd is defined earlier\n",
    "    JAVA_SERVICE_PATH = os.path.join(cwd, 'source/java')\n",
    "    H2O_GENMODEL_JAR_PATH = os.path.join(JAVA_SERVICE_PATH, 'h2o-genmodel.jar')\n",
    "    GSON_JAR_PATH = os.path.join(JAVA_SERVICE_PATH, 'gson-2.8.8.jar')\n",
    "    MAIN_JAVA_FILE_PATH = os.path.join(JAVA_SERVICE_PATH, 'main1.java')\n",
    "\n",
    "    # Check if Java files and JARs exist\n",
    "    if not os.path.exists(H2O_GENMODEL_JAR_PATH):\n",
    "        raise FileNotFoundError(f\"JAR file not found: {H2O_GENMODEL_JAR_PATH}\")\n",
    "    if not os.path.exists(GSON_JAR_PATH):\n",
    "        raise FileNotFoundError(f\"JAR file not found: {GSON_JAR_PATH}\")\n",
    "    if not os.path.exists(MAIN_JAVA_FILE_PATH):\n",
    "        raise FileNotFoundError(f\"Java file not found: {MAIN_JAVA_FILE_PATH}\")\n",
    "\n",
    "    # Use the correct classpath separator\n",
    "    classpath_separator = os.pathsep\n",
    "    classpath = f'.{classpath_separator}{H2O_GENMODEL_JAR_PATH}{classpath_separator}{GSON_JAR_PATH}'\n",
    "\n",
    "    predictions_and_stats_list = []\n",
    "\n",
    "    try:\n",
    "        for item in csv_for_result:\n",
    "            compile_command = ['javac', '-cp', classpath, 'main1.java']\n",
    "            subprocess.run(compile_command, cwd=JAVA_SERVICE_PATH, check=True)\n",
    "            # Execute the Java code and capture the output\n",
    "            run_command = ['java', '-cp', classpath, 'main1', item]\n",
    "            result = subprocess.run(run_command, cwd=JAVA_SERVICE_PATH, capture_output=True, text=True)\n",
    "            if result.returncode != 0:\n",
    "                raise RuntimeError(f\"Java execution failed with code {result.returncode}\")\n",
    "\n",
    "            # Process the output (assuming it's JSON)\n",
    "            predictions_and_stats = json.loads(result.stdout)\n",
    "            # Round statistical metrics to the nearest integer\n",
    "            rounded_predictions = {metric: round(value) for metric, value in predictions_and_stats.items()}\n",
    "            predictions_and_stats_list.append(rounded_predictions)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error executing Java code: {e}\")\n",
    "        raise RuntimeError('Error executing Java code') from e  # Handle error as needed\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON output from Java: {e}\")\n",
    "        raise RuntimeError('Error decoding JSON output from Java') from e\n",
    "    return predictions_and_stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\trails\\\\kalamath_model_jupyter_package_testing\\\\source/csv_files\\\\csv_for_stand_101.csv', 'd:\\\\trails\\\\kalamath_model_jupyter_package_testing\\\\source/csv_files\\\\csv_for_stand_102.csv', 'd:\\\\trails\\\\kalamath_model_jupyter_package_testing\\\\source/csv_files\\\\csv_for_stand_103.csv', 'd:\\\\trails\\\\kalamath_model_jupyter_package_testing\\\\source/csv_files\\\\csv_for_stand_104.csv', 'd:\\\\trails\\\\kalamath_model_jupyter_package_testing\\\\source/csv_files\\\\csv_for_stand_105.csv', 'd:\\\\trails\\\\kalamath_model_jupyter_package_testing\\\\source/csv_files\\\\csv_for_stand_106.csv', 'd:\\\\trails\\\\kalamath_model_jupyter_package_testing\\\\source/csv_files\\\\csv_for_stand_107.csv'] ['101', '102', '103', '104', '105', '106', '107']\n"
     ]
    }
   ],
   "source": [
    "# Folder path\n",
    "folder_path = os.path.join(os.getcwd(), \"source/csv_files\")\n",
    "csv_for_result, stand_id_result = filter_csv(folder_path)\n",
    "\n",
    "print(csv_for_result, stand_id_result)\n",
    "predictions_and_stats_list = prediction(csv_for_result)\n",
    "df = pd.DataFrame(predictions_and_stats_list)\n",
    "df['StandId'] = [items for items in stand_id_result]\n",
    "\n",
    "# Move 'StandId' to the first column\n",
    "cols = ['StandId'] + [col for col in df.columns if col != 'StandId']\n",
    "df = df[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StandId</th>\n",
       "      <th>mode</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>highestValue</th>\n",
       "      <th>lowestValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>634</td>\n",
       "      <td>625</td>\n",
       "      <td>614</td>\n",
       "      <td>703</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>532</td>\n",
       "      <td>481</td>\n",
       "      <td>483</td>\n",
       "      <td>668</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>685</td>\n",
       "      <td>626</td>\n",
       "      <td>610</td>\n",
       "      <td>719</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>571</td>\n",
       "      <td>571</td>\n",
       "      <td>571</td>\n",
       "      <td>674</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>508</td>\n",
       "      <td>515</td>\n",
       "      <td>548</td>\n",
       "      <td>807</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>497</td>\n",
       "      <td>483</td>\n",
       "      <td>469</td>\n",
       "      <td>695</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>616</td>\n",
       "      <td>646</td>\n",
       "      <td>644</td>\n",
       "      <td>854</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StandId  mode  median  mean  highestValue  lowestValue\n",
       "0     101   634     625   614           703          429\n",
       "1     102   532     481   483           668          308\n",
       "2     103   685     626   610           719          428\n",
       "3     104   571     571   571           674          365\n",
       "4     105   508     515   548           807          420\n",
       "5     106   497     483   469           695          305\n",
       "6     107   616     646   644           854          422"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stats with current TPA and current SDImax'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StandId</th>\n",
       "      <th>Curr_SDImax</th>\n",
       "      <th>Curr_QMD</th>\n",
       "      <th>Curr_TPA</th>\n",
       "      <th>%SDImax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>950</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>73.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>394</td>\n",
       "      <td>11</td>\n",
       "      <td>400</td>\n",
       "      <td>101.522843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>482</td>\n",
       "      <td>12</td>\n",
       "      <td>390</td>\n",
       "      <td>80.912863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StandId  Curr_SDImax  Curr_QMD  Curr_TPA     %SDImax\n",
       "0     101          950         8       700   73.684211\n",
       "1     102          394        11       400  101.522843\n",
       "2     103          482        12       390   80.912863"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Folder path\n",
    "folder_path = modified_csv_folder\n",
    "csv_for_result, stand_id_result = filter_csv(folder_path)\n",
    "# print(csv_for_result)\n",
    "df2=None\n",
    "if csv_for_result != [] and stand_id_result != []:\n",
    "    predictions_and_stats_list = prediction(csv_for_result)\n",
    "    df2 = pd.DataFrame(predictions_and_stats_list)\n",
    "    df2['StandId'] = [items for items in stand_id_result]\n",
    "    df2['Curr_QMD'] = [int(values[0]) for item, values in dict_for_standIDnCrrnQMD_from_allFields.items()]\n",
    "    df2['Curr_TPA'] = [int(values[1]) for item, values in dict_for_standIDnCrrnQMD_from_allFields.items()]\n",
    "    # Move 'StandId' to the first column\n",
    "    cols = ['StandId'] + [col for col in df2.columns if col != 'StandId']\n",
    "    df2 = df2[['StandId','median', 'Curr_QMD','Curr_TPA' ]]\n",
    "    df2 = df2.rename(columns={'median': 'Curr_SDImax'})\n",
    "    df2['%SDImax'] =  (df2['Curr_TPA'] * 100 )/ df2['Curr_SDImax']\n",
    "    display(\"stats with current TPA and current SDImax\")\n",
    "    display(df2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StandId</th>\n",
       "      <th>mode</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>highestValue</th>\n",
       "      <th>lowestValue</th>\n",
       "      <th>Curr_SDImax</th>\n",
       "      <th>Curr_QMD</th>\n",
       "      <th>Curr_TPA</th>\n",
       "      <th>%SDImax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>634</td>\n",
       "      <td>625</td>\n",
       "      <td>614</td>\n",
       "      <td>703</td>\n",
       "      <td>429</td>\n",
       "      <td>950.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>73.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102</td>\n",
       "      <td>532</td>\n",
       "      <td>481</td>\n",
       "      <td>483</td>\n",
       "      <td>668</td>\n",
       "      <td>308</td>\n",
       "      <td>394.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>101.522843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>685</td>\n",
       "      <td>626</td>\n",
       "      <td>610</td>\n",
       "      <td>719</td>\n",
       "      <td>428</td>\n",
       "      <td>482.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>80.912863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104</td>\n",
       "      <td>571</td>\n",
       "      <td>571</td>\n",
       "      <td>571</td>\n",
       "      <td>674</td>\n",
       "      <td>365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>105</td>\n",
       "      <td>508</td>\n",
       "      <td>515</td>\n",
       "      <td>548</td>\n",
       "      <td>807</td>\n",
       "      <td>420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106</td>\n",
       "      <td>497</td>\n",
       "      <td>483</td>\n",
       "      <td>469</td>\n",
       "      <td>695</td>\n",
       "      <td>305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>107</td>\n",
       "      <td>616</td>\n",
       "      <td>646</td>\n",
       "      <td>644</td>\n",
       "      <td>854</td>\n",
       "      <td>422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StandId  mode  median  mean  highestValue  lowestValue  Curr_SDImax  \\\n",
       "0     101   634     625   614           703          429        950.0   \n",
       "1     102   532     481   483           668          308        394.0   \n",
       "2     103   685     626   610           719          428        482.0   \n",
       "3     104   571     571   571           674          365          NaN   \n",
       "4     105   508     515   548           807          420          NaN   \n",
       "5     106   497     483   469           695          305          NaN   \n",
       "6     107   616     646   644           854          422          NaN   \n",
       "\n",
       "   Curr_QMD  Curr_TPA     %SDImax  \n",
       "0       8.0     700.0   73.684211  \n",
       "1      11.0     400.0  101.522843  \n",
       "2      12.0     390.0   80.912863  \n",
       "3       NaN       NaN         NaN  \n",
       "4       NaN       NaN         NaN  \n",
       "5       NaN       NaN         NaN  \n",
       "6       NaN       NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if df2 is not None:\n",
    "    merged_df = pd.merge(df, df2, how='outer', on='StandId')\n",
    "    merged_df = merged_df.rename(columns={'Curr_SDImax_x': 'median', 'Curr_SDImax_y': 'Curr_SDImax'})\n",
    "    display(merged_df)  \n",
    "    result_folder = os.path.join(cwd,'result/result_with_current_QMD_and_TPA.csv')\n",
    "    df.to_csv(result_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = os.path.join(cwd,'result/result.csv')\n",
    "df.to_csv(result_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
